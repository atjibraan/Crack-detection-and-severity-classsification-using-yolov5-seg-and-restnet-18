# -*- coding: utf-8 -*-
"""CS2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Et5iZ9sHqGFxYRIzfWyD6rj4DYdVBZ5g
"""

from google.colab import drive
drive.mount('/content/drive')

"""# New section

# New section
"""



# Install necessary dependencies
!pip install roboflow torch torchvision pyyaml

# Import Roboflow and download dataset
from roboflow import Roboflow
rf = Roboflow(api_key="9a6Wn160mOa8Q8T2y1Ji")
project = rf.workspace("university-bswxt").project("crack-bphdr")
version = project.version(2)
dataset = version.download("yolov5")

# Commented out IPython magic to ensure Python compatibility.
# Clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5.git
# %cd yolov5

!pip install -r requirements.txt

# Create yolov5-seg.yaml configuration file
import yaml

seg_yaml_path = "models/yolov5-seg.yaml"
seg_config = {
    'nc': 1,  # Number of classes (1 for cracks)
    'depth_multiple': 0.33,
    'width_multiple': 0.50,
    'anchors': [[10,13, 16,30, 33,23], [30,61, 62,45, 59,119], [116,90, 156,198, 373,326]],
    'backbone': [[-1, 1, "Focus", [64, 3]], [-1, 1, "Conv", [128, 3, 2]], [-1, 3, "C3", [128]], [-1, 1, "Conv", [256, 3, 2]], [-1, 6, "C3", [256]], [-1, 1, "Conv", [512, 3, 2]], [-1, 9, "C3", [512]], [-1, 1, "Conv", [1024, 3, 2]], [-1, 3, "C3", [1024]], [-1, 1, "SPP", [1024, [5, 9, 13]]], [-1, 1, "Conv", [512, 1, 1]], [-1, 1, "nn.Upsample", [None, 2, 'nearest']], [[-1, 6], 1, "Concat", [1]], [-1, 3, "C3", [512, False]], [-1, 1, "Conv", [256, 1, 1]], [-1, 1, "nn.Upsample", [None, 2, 'nearest']], [[-1, 4], 1, "Concat", [1]], [-1, 3, "C3", [256, False]]],
    'head': [[-1, 1, "Conv", [256, 3, 1]], [-1, 1, "nn.Upsample", [None, 2, 'nearest']], [[-1, 14], 1, "Concat", [1]], [-1, 3, "C3", [256, False]], [-1, 1, "Conv", [256, 3, 1]], [[-1, 10], 1, "Concat", [1]], [-1, 3, "C3", [512, False]], [-1, 1, "Conv", [512, 3, 1]], [[-1, 6], 1, "Concat", [1]], [-1, 3, "C3", [1024, False]], [[17, 20, 23], 1, "Detect", [1, [[10,13, 16,30, 33,23], [30,61, 62,45, 59,119], [116,90, 156,198, 373,326]]]]]
}

with open(seg_yaml_path, 'w') as file:
    yaml.dump(seg_config, file, default_flow_style=False)

print("Created yolov5-seg.yaml")

# Update data.yaml paths
data_yaml_path = "/content/crack-2/data.yaml"
with open(data_yaml_path, 'r') as file:
    data = yaml.safe_load(file)

# Set correct paths
data['train'] = "/content/crack-2/train/images"
data['val'] = "/content/crack-2/valid/images"
data['test'] = "/content/crack-2/test/images"
data['nc'] = 1  # Number of classes (1 for cracks)
data['names'] = ["crack"]

with open(data_yaml_path, 'w') as file:
    yaml.dump(data, file)

print("Updated data.yaml:", data)

!python segment/train.py --weights yolov5s-seg.pt --data {data_yaml_path} --epochs 50 --batch-size 8 --device 0 --cache --patience 10

/content/yolov5/runs/train-seg/exp3/weights/best.pt



!python detect.py --/content/yolov5/runs/train-seg/exp3/weights/best.pt--source /content/crack-2/test/images/1616.rf.c868709931a671796794fdbb95352c5a.jpg --conf 0.5

from IPython.display import display
from PIL import Image

image_path = "/content/crack-2/test/images/1616.rf.c868709931a671796794fdbb95352c5a.jpg"
display(Image.open(image_path))

!python detect.py --weights /content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1616.rf.c868709931a671796794fdbb95352c5a.jpg --conf 0.3

# final

ls /content/yolov5

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5
!python detect.py --weights /content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1960.rf.a23272eb27c0f5ab6327f98571919ad9.jpg --conf 0.3

!python detect.py --weights /content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1686.rf.809fb1b51c607e5cf787e44ef4ddd7b8.jpg --conf 0.3

from google.colab import files
files.download('/content/yolov5/runs/train-seg/exp3/weights/best.pt')

!python detect.py --weights runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1616.rf.c868709931a671796794fdbb95352c5a.jpg --conf 0.5 --save-crop

import torch

checkpoint = torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=torch.device('cpu'))
print(type(checkpoint))

import torch
import torch.nn as nn
import torchvision.models as models

# Define the same model architecture as in Jupyter
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(pretrained=True)  # Load ResNet-18
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 output classes (No Crack, Mild, Moderate, Severe)

# Load the saved weights
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))

# Move model to device and set to eval mode
model = model.to(device)
model.eval()

print("[INFO] Model successfully loaded and ready for inference!")





!cd /

!ls -l

!cp -r /content/crack2 /content/drive/MyDrive/
!cp -r /content/yolov5 /content/drive/MyDrive/

## Inference pipeline

/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt

/content/drive/MyDrive/cracked_surface.jpg

import os

os.chdir('/content/drive/MyDrive/yolov5')

import torch
from models.experimental import attempt_load

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load model correctly
model_path = "/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt"

# Load the model without map_location, and then move to device
model = attempt_load(model_path)  # Remove map_location
model = model.to(device)  # Move the model to the desired device

model.eval()  # Set to evaluation mode

test_output = model(torch.zeros(1, 3, 640, 640).to(device))
print(len(test_output))  # Should be 2 (bbox + masks)

!python detect.py --weights runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1686.rf.809fb1b51c607e5cf787e44ef4ddd7b8.jpg --conf 0.3

!python detect.py --weights runs/train-seg/exp3/weights/best.pt --source /content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4 --conf 0.3

!python detect.py --/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt--source "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4" --conf 0.3

!python detect.py --weights "/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt" --source "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4" --conf 0.3

!python detect.py --weights "/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt" \
--source "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4" \
--conf 0.3 --save-txt --save-conf --save-crop --project runs/detect --name crack_video

from models.common import DetectMultiBackend
import torch
import cv2
import numpy as np
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # Required for Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Open video file
video_path = "/content/drive/MyDrive/tv5.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video reached.")
        break

    # Resize frame for YOLO model
    frame_resized = letterbox(frame, 640, stride=32, auto=True)[0]
    frame_resized = np.ascontiguousarray(frame_resized)

    # Convert to tensor and add batch dimension
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)

    # Run YOLOv5 Crack Detection
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.5)

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            boxes = det[:, :4]  # Extract bounding box coordinates
            scores = det[:, 4]  # Extract confidence scores

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                if scores[i] > 0.5:
                    detected_cracks = True
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
                    cv2.putText(frame, "Crack", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # Show frame using cv2_imshow (for Colab)
    cv2_imshow(frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

from models.common import DetectMultiBackend
import torch
import cv2
import numpy as np
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # For displaying in Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Open video file
video_path = "/content/drive/MyDrive/tv5.mp4"
cap = cv2.VideoCapture(video_path)

# Get video properties
fps = int(cap.get(cv2.CAP_PROP_FPS))
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
output_path = "output_video.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video reached.")
        break

    # Resize frame for YOLO model
    frame_resized = letterbox(frame, 640, stride=32, auto=True)[0]
    frame_resized = np.ascontiguousarray(frame_resized)  # Ensure correct format

    # Convert to tensor and normalize
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # 🔹 Run YOLOv5 Model for Crack Segmentation
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.5)

    # Draw bounding boxes
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            for x1, y1, x2, y2, conf, cls in det:
                if conf > 0.3:  # Confidence threshold
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
                    cv2.putText(frame, f"Crack ({conf:.2f})", (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

    # ✅ Save video
    out.write(frame)
    cv2_imshow(frame)  # Show frame in Colab

cap.release()
out.release()
cv2.destroyAllWindows()

print(f"✅ Processing complete! Output saved as: {output_path}")



from IPython.display import display, HTML
import cv2
import base64

video_path = "/content/yolov5/runs/detect/crack_video2/WhatsApp_Video.mp4"

def show_video(video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Video file not found or cannot be opened.")
        return

    cap.release()

    video_html = f"""
    <video width="640" height="480" controls>
        <source src="{video_path}" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    """
    display(HTML(video_html))

show_video(video_path)

!ls /content/yolov5/runs/detect/crack_video2/

from IPython.display import display, HTML

video_path = "/content/yolov5/runs/detect/crack_video2/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4"
video_html = f"""
<video width="640" height="480" controls>
    <source src="{video_path}" type="video/mp4">
    Your browser does not support the video tag.
</video>
"""
display(HTML(video_html))

from google.colab import files

video_path = "/content/yolov5/runs/detect/crack_video2/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4"
files.download(video_path)

!pip install ultralytics

!pip uninstall ultralytics -y

git clone https://github.com/ultralytics/yolov5.git
cd yolov5
pip install -r requirements.txt

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
from PIL import Image
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # ✅ Required for Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load ResNet-18 Crack Severity Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels
severity_labels = {0: "No Crack", 1: "Mild", 2: "Moderate", 3: "Severe"}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Open video file
video_path = "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("End of video reached.")
        break

    # Resize frame for YOLO model
    frame_resized = letterbox(frame, 640, stride=32, auto=True)[0]  # Ensure correct input shape
    frame_resized = np.ascontiguousarray(frame_resized)  # Convert for compatibility

    # Convert to tensor and add batch dimension
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0  # Normalize
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # 🔹 Step 1: YOLOv5 Crack Detection with NMS
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.5)

    detected_cracks = False
    for det in results:
        if det is not None and len(det):  # ✅ Fixed AttributeError issue
            det = det.cpu().numpy()
            boxes = det[:, :4]  # Extract bounding box coordinates
            scores = det[:, 4]  # Extract confidence scores

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                if scores[i] > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # 🔹 Step 2: Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_index = torch.argmax(output).item()
                        severity_label = severity_labels[severity_index]

                    # Draw bounding box and label
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, severity_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # ✅ Show frame using cv2_imshow (for Colab)
    cv2_imshow(frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
from PIL import Image
from utils.general import non_max_suppression, scale_boxes
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # ✅ Required for Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load ResNet-18 Crack Severity Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels
severity_labels = {0: "No Crack", 1: "Mild", 2: "Moderate", 3: "Severe"}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Open video file
video_path = "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

while cap.isOpened():
    ret, frame = cap.read()

    # 🔹 Stopping Condition: End video if no frame
    if not ret:
        print("End of video reached.")
        break

    orig_h, orig_w = frame.shape[:2]  # Original frame size

    # Resize frame for YOLO model (letterbox for proper shape)
    frame_resized, ratio, (dw, dh) = letterbox(frame, 640, stride=32, auto=False)
    frame_resized = np.ascontiguousarray(frame_resized)  # Ensure correct input shape

    # Convert to tensor and normalize
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # 🔹 Step 1: YOLOv5 Crack Detection with Corrected Bounding Boxes
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.5)

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            det[:, :4] = scale_boxes(img_tensor.shape[2:], det[:, :4], frame.shape).round()  # ✅ Fix Bounding Box Scaling
            boxes = det[:, :4]
            scores = det[:, 4]

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                if scores[i] > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # 🔹 Step 2: Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_index = torch.argmax(output).item()
                        severity_label = severity_labels[severity_index]

                    # Choose color based on severity
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)

                    # Draw bounding box and severity label (✅ Corrected Positioning)
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, severity_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # ✅ Show frame using cv2_imshow (for Colab)
    cv2_imshow(frame)

    # 🔹 Stopping Condition: Exit on 'q' Key Press
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        print("User exited by pressing 'q'.")
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
from PIL import Image
from utils.general import non_max_suppression, scale_boxes
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # Import for displaying images in Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load ResNet-18 Crack Severity Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels
severity_labels = {0: "No Crack", 1: "Mild", 2: "Moderate", 3: "Severe"}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Increased size for better classification
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Video file path
video_source = "/content/drive/MyDrive/tv5.mp4"
output_video_path = "/content/drive/MyDrive/crack_output5.mp4"

# Open video capture
cap = cv2.VideoCapture(video_source)
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define VideoWriter
overlay = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    orig_h, orig_w = frame.shape[:2]  # Original frame size

    # Resize frame for YOLO model (letterbox for proper shape)
    frame_resized, ratio, (dw, dh) = letterbox(frame, 640, stride=32, auto=False)
    frame_resized = np.ascontiguousarray(frame_resized)  # Ensure correct input shape

    # Convert to tensor and normalize
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # YOLOv5 Crack Detection with Corrected Bounding Boxes
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.3)  # Adjusted confidence threshold

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            det[:, :4] = scale_boxes(img_tensor.shape[2:], det[:, :4], frame.shape).round()  # Fix Bounding Box Scaling
            boxes = det[:, :4]
            scores = det[:, 4]

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                confidence = scores[i]  # Extract confidence score for detection
                if confidence > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_probs = torch.softmax(output, dim=1).cpu().numpy()[0]
                        severity_index = np.argmax(severity_probs)
                        severity_label = severity_labels[severity_index]
                        severity_confidence = severity_probs[severity_index]  # Confidence for severity

                    # Choose color based on severity
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)

                    # Draw bounding box, severity label, and confidence scores
                    label = f"{severity_label} ({severity_confidence:.2f}, Det: {confidence:.2f})"
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # Write frame to output video
    overlay.write(frame)

    # Show frame using cv2_imshow for Colab
    cv2_imshow(frame)

cap.release()
overlay.release()
cv2.destroyAllWindows()
print(f"Processed video saved to {output_video_path}")

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
from PIL import Image
from utils.general import non_max_suppression, scale_boxes
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # Import for displaying images in Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load ResNet-18 Crack Severity Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels
severity_labels = {0: "No Crack", 1: "Mild", 2: "Moderate", 3: "Severe"}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Increased size for better classification
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Video file path
video_source = "/content/drive/MyDrive/tv3.mp4"
output_video_path = "/content/drive/MyDrive/crack_output4.mp4"

# Open video capture
cap = cv2.VideoCapture(video_source)
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define VideoWriter
overlay = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    orig_h, orig_w = frame.shape[:2]  # Original frame size

    # Resize frame for YOLO model (letterbox for proper shape)
    frame_resized, ratio, (dw, dh) = letterbox(frame, 640, stride=32, auto=False)
    frame_resized = np.ascontiguousarray(frame_resized)  # Ensure correct input shape

    # Convert to tensor and normalize
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # YOLOv5 Crack Detection with Corrected Bounding Boxes
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.3)  # Adjusted confidence threshold

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            det[:, :4] = scale_boxes(img_tensor.shape[2:], det[:, :4], frame.shape).round()  # Fix Bounding Box Scaling
            boxes = det[:, :4]
            scores = det[:, 4]

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                confidence = scores[i]  # Extract confidence score for detection
                if confidence > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_probs = torch.softmax(output, dim=1).cpu().numpy()[0]
                        severity_index = np.argmax(severity_probs)
                        severity_label = severity_labels[severity_index]
                        severity_confidence = severity_probs[severity_index]  # Confidence for severity

                    # Choose color based on severity
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)

                    # Draw bounding box, severity label, and confidence scores
                    label = f"{severity_label} ({severity_confidence:.2f}, Det: {confidence:.2f})"
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # Write frame to output video
    overlay.write(frame)

    # Show frame using cv2_imshow for Colab
    cv2_imshow(frame)

cap.release()
overlay.release()
cv2.destroyAllWindows()
print(f"Processed video saved to {output_video_path}")

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
from PIL import Image
from utils.general import non_max_suppression, scale_boxes
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # Import for displaying images in Colab

# Load YOLOv5 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load ResNet-18 Crack Severity Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels with repair suggestions
severity_labels = {
    0: ("No Crack", "No repair needed"),
    1: ("Mild", "Apply sealant to prevent further damage"),
    2: ("Moderate", "Consider resurfacing or patching the affected area"),
    3: ("Severe", "Structural repair needed, consult an engineer")
}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Increased size for better classification
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Video file path
video_source = "/content/drive/MyDrive/WhatsApp Video 2025-03-12 at 13.16.00_69d8b651.mp4"
output_video_path = "/content/drive/MyDrive/crack_output2.mp4"

# Open video capture
cap = cv2.VideoCapture(video_source)
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define VideoWriter
overlay = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    orig_h, orig_w = frame.shape[:2]  # Original frame size

    # Resize frame for YOLO model (letterbox for proper shape)
    frame_resized, ratio, (dw, dh) = letterbox(frame, 640, stride=32, auto=False)
    frame_resized = np.ascontiguousarray(frame_resized)  # Ensure correct input shape

    # Convert to tensor and normalize
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

    # YOLOv5 Crack Detection with Corrected Bounding Boxes
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.3)  # Adjusted confidence threshold

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            det[:, :4] = scale_boxes(img_tensor.shape[2:], det[:, :4], frame.shape).round()  # Fix Bounding Box Scaling
            boxes = det[:, :4]
            scores = det[:, 4]

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                confidence = scores[i]  # Extract confidence score for detection
                if confidence > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_probs = torch.softmax(output, dim=1).cpu().numpy()[0]
                        severity_index = np.argmax(severity_probs)
                        severity_label, repair_suggestion = severity_labels[severity_index]
                        severity_confidence = severity_probs[severity_index]  # Confidence for severity

                    # Choose color based on severity
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)

                    # Draw bounding box, severity label, and confidence scores
                    label = f"{severity_label} ({severity_confidence:.2f}, Det: {confidence:.2f})"
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                    cv2.putText(frame, repair_suggestion, (int(x1), int(y2) + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # Write frame to output video
    overlay.write(frame)

    # Show frame using cv2_imshow for Colab
    cv2_imshow(frame)

cap.release()
overlay.release()
cv2.destroyAllWindows()
print(f"Processed video saved to {output_video_path}")

!python detect.py --weights /content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1960.rf.a23272eb27c0f5ab6327f98571919ad9.jpg  --conf 0.3

!python detect.py --weights /content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt --source /content/crack-2/test/images/1616.rf.c868709931a671796794fdbb95352c5a.jpg --conf 0.5 --save-crop

# prompt: unmount drive

from google.colab import drive
drive.flush_and_unmount()

# prompt: mount drive

from google.colab import drive
drive.mount('/content/drive')

import torch
import cv2
import numpy as np
from models.common import DetectMultiBackend
from utils.general import non_max_suppression, scale_boxes
from utils.augmentations import letterbox

# Check if running in Google Colab
try:
    from google.colab.patches import cv2_imshow
    in_colab = True
except ImportError:
    in_colab = False

# Load YOLOv5 model for crack detection
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# Load and process the image
image_path = "/content/crack-2/test/images/1896.rf.e718dd26abc98c2645ea37a808039034.jpg"  # Change to your test image path
frame = cv2.imread(image_path)

# Resize image for YOLO model (letterbox for correct aspect ratio)
frame_resized, ratio, (dw, dh) = letterbox(frame, 640, stride=32, auto=False)
frame_resized = np.ascontiguousarray(frame_resized)

# Convert image to tensor
img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0
img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (H, W, C) → (1, C, H, W)

# Run YOLO model for crack detection
detections = yolo_model(img_tensor)
results = non_max_suppression(detections, conf_thres=0.2, iou_thres=0.3)  # Lowered confidence threshold

print(f"Raw Model Output: {detections}")  # Debugging: Print raw model output

detected_cracks = False
for det in results:
    if det is not None and len(det):
        det = det.cpu().numpy()
        det[:, :4] = scale_boxes(img_tensor.shape[2:], det[:, :4], frame.shape).round()  # Fix bounding boxes
        boxes = det[:, :4]
        scores = det[:, 4]

        print(f"Detected Boxes: {boxes}")  # Debugging: Print detected bounding boxes

        for i, (x1, y1, x2, y2) in enumerate(boxes):
            confidence = scores[i]  # Confidence score for detection
            if confidence > 0.2:
                detected_cracks = True

                # Draw bounding box
                color = (0, 0, 255)  # Red color for detected cracks
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                label = f"Crack ({confidence:.2f})"
                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

if not detected_cracks:
    cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

# Display the processed image
if in_colab:
    cv2_imshow(frame)  # Google Colab
else:
    cv2.imshow("Crack Detection", frame)  # Local
    cv2.waitKey(0)
    cv2.destroyAllWindows()

from models.common import DetectMultiBackend
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
import numpy as np
from PIL import Image
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from google.colab.patches import cv2_imshow  # ✅ Required for Colab

# 🔹 Load YOLOv5 Model for Crack Detection
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
yolo_model = DetectMultiBackend("/content/drive/MyDrive/yolov5/runs/train-seg/exp3/weights/best.pt", device=device)

# 🔹 Load ResNet-18 Crack Severity Classification Model
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 4)  # 4 classes: No Crack, Mild, Moderate, Severe
model.load_state_dict(torch.load("/content/drive/MyDrive/crack_severity_model.pth", map_location=device))
model.to(device)
model.eval()

# Severity labels
severity_labels = {0: "No Crack", 1: "Mild", 2: "Moderate", 3: "Severe"}

# Define transformation for ResNet model
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# 🔹 Open External Webcam
cap = cv2.VideoCapture(1)  # Change to 0 if your webcam is at index 0

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Error: Failed to capture image")
        break

    # Resize frame for YOLO model
    frame_resized = letterbox(frame, 640, stride=32, auto=True)[0]  # Resize while keeping aspect ratio
    frame_resized = np.ascontiguousarray(frame_resized)  # Convert for compatibility

    # Convert frame to tensor
    img_tensor = torch.from_numpy(frame_resized).to(device).float() / 255.0  # Normalize to [0,1]
    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # Convert (H, W, C) → (1, C, H, W)

    # 🔹 Step 1: YOLOv5 Crack Detection with NMS
    detections = yolo_model(img_tensor)
    results = non_max_suppression(detections, conf_thres=0.5, iou_thres=0.5)

    detected_cracks = False
    for det in results:
        if det is not None and len(det):
            det = det.cpu().numpy()
            boxes = det[:, :4]  # Extract bounding box coordinates
            scores = det[:, 4]  # Extract confidence scores

            for i, (x1, y1, x2, y2) in enumerate(boxes):
                if scores[i] > 0.5:
                    detected_cracks = True

                    # Extract ROI for severity classification
                    roi = frame[int(y1):int(y2), int(x1):int(x2)]
                    if roi.size == 0:
                        continue

                    # 🔹 Step 2: Crack Severity Classification
                    roi_pil = Image.fromarray(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))
                    roi_tensor = transform(roi_pil).unsqueeze(0).to(device)

                    with torch.no_grad():
                        output = model(roi_tensor)
                        severity_index = torch.argmax(output).item()
                        severity_label = severity_labels[severity_index]

                    # Draw bounding box and label
                    color = (0, 255, 0) if severity_label == "Mild" else (0, 255, 255) if severity_label == "Moderate" else (0, 0, 255)
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, severity_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    if not detected_cracks:
        cv2.putText(frame, "No Crack Detected", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    # ✅ Show frame using cv2_imshow (for Colab)
    cv2_imshow(frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()